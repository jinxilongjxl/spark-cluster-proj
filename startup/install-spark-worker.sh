#!/bin/bash
set -e
exec > /var/log/spark-worker-install.log 2>&1

echo "===== å¼€å§‹å®‰è£…Spark Worker ====="

# 1. å®‰è£…ä¾èµ–
echo "æ­¥éª¤1ï¼šå®‰è£…Javaå’ŒSSH"
apt update -y
apt install -y openjdk-11-jdk openssh-server
systemctl enable --now ssh
echo "Javaç‰ˆæœ¬ï¼š$(java -version 2>&1 | head -1)"

# 2. åˆ›å»ºsparkç”¨æˆ·
echo "æ­¥éª¤2ï¼šåˆ›å»ºsparkç”¨æˆ·"
id spark &>/dev/null || useradd -m -s /bin/bash spark
echo "sparkç”¨æˆ·IDï¼š$(id -u spark)"

# 3. å®‰è£…Spark 3.5.7ï¼ˆç¡¬ç¼–ç è·¯å¾„ï¼Œç¡®ä¿ä¸‹è½½å’Œè§£åŽ‹ï¼‰
echo "æ­¥éª¤3ï¼šå®‰è£…Spark 3.5.7"
SPARK_INSTALL_DIR="/home/spark"
SPARK_HOME="$SPARK_INSTALL_DIR/spark"
SPARK_TAR="spark-3.5.7-bin-hadoop3.tgz"
SPARK_URL="https://dlcdn.apache.org/spark/spark-3.5.7/$SPARK_TAR"
BACKUP_URL="https://mirrors.aliyun.com/apache/spark/spark-3.5.7/$SPARK_TAR"

if [ ! -d "$SPARK_HOME" ]; then
  su - spark -c "
    cd $SPARK_INSTALL_DIR
    echo 'ðŸ“¥ ä»Žä¸»æºä¸‹è½½Sparkï¼ˆæ˜¾ç¤ºè¿›åº¦ï¼‰...'
    if ! wget --show-progress --retry-connrefused --waitretry=3 --read-timeout=30 --timeout=15 -t 5 $SPARK_URL; then
      echo 'âŒ ä¸»æºä¸‹è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æº...'
      if ! wget --show-progress --retry-connrefused --waitretry=3 --read-timeout=30 --timeout=15 -t 5 $BACKUP_URL; then
        echo 'âŒ å¤‡ç”¨æºä¸‹è½½ä¹Ÿå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥'
        exit 1
      fi
    fi
    echo 'ï¿½è§£åŽ‹Sparkå®‰è£…åŒ…...'
    if ! tar -xzf $SPARK_TAR; then
      echo 'âŒ è§£åŽ‹å¤±è´¥ï¼Œå®‰è£…åŒ…å¯èƒ½æŸå'
      exit 1
    fi
    mv spark-3.5.7-bin-hadoop3 spark
    rm -f $SPARK_TAR
    echo 'âœ… Sparkå®‰è£…æˆåŠŸ'
  "
else
  echo "âœ… Sparkå·²å®‰è£…ï¼Œè·³è¿‡æ­¤æ­¥éª¤"
fi
chown -R spark:spark $SPARK_INSTALL_DIR/spark

# 4. é…ç½®**æ°¸ä¹…ç”Ÿæ•ˆ**çš„å…¨é‡çŽ¯å¢ƒå˜é‡ï¼ˆå†™å…¥.bashrcï¼Œå¹¶å¼ºåˆ¶åŠ è½½ï¼‰
echo "æ­¥éª¤4ï¼šé…ç½®æ°¸ä¹…çŽ¯å¢ƒå˜é‡"
su - spark -c "
  cat >> ~/.bashrc << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export SPARK_HOME=/home/spark/spark
export SPARK_MASTER_HOST=spark-master
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_MEMORY=2g
export SPARK_WORKER_CORES=1
export PATH=\$PATH:\$SPARK_HOME/bin:\$SPARK_HOME/sbin
EOF
  # å¼ºåˆ¶åŠ è½½çŽ¯å¢ƒå˜é‡ï¼ˆç¡®ä¿å½“å‰ä¼šè¯å’ŒåŽç»­SSHç™»å½•è‡ªåŠ¨ç”Ÿæ•ˆï¼‰
  source ~/.bashrc
"

# æ­¥éª¤5ï¼šæ·»åŠ MasterèŠ‚ç‚¹Hostsæ˜ å°„
echo "æ­¥éª¤5ï¼šæ·»åŠ MasterèŠ‚ç‚¹Hostsæ˜ å°„"
# å°è¯•é€šè¿‡å†…éƒ¨DNSè§£æžMaster IP
MASTER_IP=$(nslookup spark-master | grep 'Address: ' | tail -n 1 | awk '{print $2}')
if [ -z "$MASTER_IP" ]; then
  echo "âŒ å†…éƒ¨DNSè§£æžå¤±è´¥ï¼Œæ‰‹åŠ¨æŒ‡å®šMaster IPï¼ˆä»ŽTerraformè¾“å‡ºæˆ–GCPæŽ§åˆ¶å°èŽ·å–ï¼‰"
  MASTER_IP="ä½ çš„MasterèŠ‚ç‚¹å…¬ç½‘IP"  # æ›¿æ¢ä¸ºå®žé™…IP
fi
echo "$MASTER_IP  spark-master" | sudo tee -a /etc/hosts
echo "âœ… MasterèŠ‚ç‚¹Hostsæ˜ å°„æ·»åŠ å®Œæˆï¼š$MASTER_IP  spark-master"

# 6. éªŒè¯çŽ¯å¢ƒå˜é‡åŠ è½½
echo "æ­¥éª¤6ï¼šéªŒè¯çŽ¯å¢ƒå˜é‡"
su - spark -c "
  echo 'JAVA_HOME: ' \$JAVA_HOME
  echo 'SPARK_HOME: ' \$SPARK_HOME
  echo 'SPARK_MASTER_HOST: ' \$SPARK_MASTER_HOST
  echo 'SPARK_MASTER_PORT: ' \$SPARK_MASTER_PORT
"

# 7. å‡†å¤‡SSHç›®å½•ï¼ˆç­‰å¾…Masterå…¬é’¥ï¼‰
echo "æ­¥éª¤7ï¼šåˆå§‹åŒ–SSHç›®å½•"
su - spark -c "
  mkdir -p ~/.ssh
  chmod 700 ~/.ssh
  touch ~/.ssh/authorized_keys
  chmod 600 ~/.ssh/authorized_keys
"

# 8. å¯åŠ¨Spark Workerï¼ˆç¡¬ç¼–ç è·¯å¾„+å¼ºåˆ¶åŠ è½½çŽ¯å¢ƒå˜é‡ï¼‰
echo "æ­¥éª¤8ï¼šå¯åŠ¨Spark Worker"
su - spark -c "
  # å¼ºåˆ¶åŠ è½½æœ€æ–°çŽ¯å¢ƒå˜é‡
  source ~/.bashrc
  echo 'ðŸ”— è¿žæŽ¥åˆ°MasterèŠ‚ç‚¹ï¼š\$SPARK_MASTER_HOST:\$SPARK_MASTER_PORT'
  # ç¡¬ç¼–ç å®Œæ•´å¯åŠ¨è„šæœ¬è·¯å¾„
  /home/spark/spark/sbin/start-worker.sh spark://\$SPARK_MASTER_HOST:\$SPARK_MASTER_PORT
  echo 'âœ… Spark Workerå¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œï¼Œè¿›ç¨‹çŠ¶æ€å¯é€šè¿‡jpsæˆ–æ—¥å¿—æ£€æŸ¥'
"

echo "===== Spark Workerå®‰è£…åŠå¯åŠ¨å®Œæˆ ====="