#!/bin/bash
set -e
exec > /var/log/spark-worker-install.log 2>&1

echo "===== å¼€å§‹å®‰è£…Spark Worker ====="

# 1. å®‰è£…ä¾èµ–
echo "æ­¥éª¤1ï¼šå®‰è£…Javaå’ŒSSH"
apt update -y
apt install -y openjdk-11-jdk openssh-server
systemctl enable --now ssh
echo "Javaç‰ˆæœ¬ï¼š$(java -version 2>&1 | head -1)"

# 2. åˆ›å»ºsparkç”¨æˆ·
echo "æ­¥éª¤2ï¼šåˆ›å»ºsparkç”¨æˆ·"
id spark &>/dev/null || useradd -m -s /bin/bash spark
echo "sparkç”¨æˆ·IDï¼š$(id -u spark)"

# 3. å®‰è£…Spark 3.5.7ï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œç¦ç”¨å®‰é™æ¨¡å¼ï¼‰
echo "æ­¥éª¤3ï¼šå®‰è£…Spark 3.5.7"
SPARK_HOME="/home/spark/spark"
SPARK_TAR="spark-3.5.7-bin-hadoop3.tgz"
SPARK_URL="https://dlcdn.apache.org/spark/spark-3.5.7/$SPARK_TAR"
# å¤‡ç”¨æºï¼ˆå›½å†…åŠ é€Ÿï¼‰
BACKUP_URL="https://mirrors.aliyun.com/apache/spark/spark-3.5.7/$SPARK_TAR"

if [ ! -d "$SPARK_HOME" ]; then
  su - spark -c "
    cd /home/spark
    echo 'ðŸ“¥ ä»Žä¸»æºä¸‹è½½Sparkï¼ˆæ˜¾ç¤ºè¿›åº¦ï¼‰...'
    if ! wget --show-progress --retry-connrefused --waitretry=3 --read-timeout=30 --timeout=15 -t 5 $SPARK_URL; then
      echo 'âŒ ä¸»æºä¸‹è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æº...'
      if ! wget --show-progress --retry-connrefused --waitretry=3 --read-timeout=30 --timeout=15 -t 5 $BACKUP_URL; then
        echo 'âŒ å¤‡ç”¨æºä¸‹è½½ä¹Ÿå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥'
        exit 1
      fi
    fi
    echo 'ï¿½è§£åŽ‹Sparkå®‰è£…åŒ…...'
    if ! tar -xzf $SPARK_TAR; then
      echo 'âŒ è§£åŽ‹å¤±è´¥ï¼Œå®‰è£…åŒ…å¯èƒ½æŸå'
      exit 1
    fi
    mv spark-3.5.7-bin-hadoop3 spark
    rm -f $SPARK_TAR  # æ¸…ç†å®‰è£…åŒ…
    echo 'âœ… Sparkå®‰è£…æˆåŠŸ'
  "
else
  echo "âœ… Sparkå·²å®‰è£…ï¼Œè·³è¿‡æ­¤æ­¥éª¤"
fi
chown -R spark:spark /home/spark/spark

# 4. é…ç½®çŽ¯å¢ƒå˜é‡
echo "æ­¥éª¤4ï¼šé…ç½®çŽ¯å¢ƒå˜é‡"
su - spark -c "
  cat >> ~/.bashrc << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export SPARK_HOME=/home/spark/spark
export PATH=\$PATH:\$SPARK_HOME/bin:\$SPARK_HOME/sbin
EOF
"

# 5. é…ç½®Spark
echo "æ­¥éª¤5ï¼šé…ç½®spark-env.sh"
su - spark -c "
  cp \$SPARK_HOME/conf/spark-env.sh.template \$SPARK_HOME/conf/spark-env.sh
  cat >> \$SPARK_HOME/conf/spark-env.sh << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export SPARK_MASTER_HOST=spark-master
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_MEMORY=2g
export SPARK_WORKER_CORES=1
EOF
"

# 6. å‡†å¤‡SSHç›®å½•ï¼ˆç­‰å¾…Masterå…¬é’¥ï¼‰
echo "æ­¥éª¤6ï¼šåˆå§‹åŒ–SSHç›®å½•"
su - spark -c "
  mkdir -p ~/.ssh
  chmod 700 ~/.ssh
  touch ~/.ssh/authorized_keys
  chmod 600 ~/.ssh/authorized_keys
"

echo "===== Spark Workerå®‰è£…å®Œæˆ ====="