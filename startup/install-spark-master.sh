#!/bin/bash
set -e
exec > /var/log/spark-master-install.log 2>&1  # æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶

echo "===== å¼€å§‹å®‰è£…Spark Master ====="

# 1. å®‰è£…ä¾èµ–
echo "æ­¥éª¤1ï¼šå®‰è£…Javaå’ŒSSH"
apt update -y
apt install -y openjdk-11-jdk openssh-server
systemctl enable --now ssh  # ç¡®ä¿SSHæœåŠ¡å¯åŠ¨
echo "Javaç‰ˆæœ¬ï¼š$(java -version 2>&1 | head -1)"

# 2. åˆ›å»ºsparkç”¨æˆ·
echo "æ­¥éª¤2ï¼šåˆ›å»ºsparkç”¨æˆ·"
id spark &>/dev/null || useradd -m -s /bin/bash spark
echo "sparkç”¨æˆ·IDï¼š$(id -u spark)"

# 3. å®‰è£…Spark 3.5.7ï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œç¦ç”¨å®‰é™æ¨¡å¼ï¼‰
echo "æ­¥éª¤3ï¼šå®‰è£…Spark 3.5.7"
SPARK_HOME="/home/spark/spark"
SPARK_TAR="spark-3.5.7-bin-hadoop3.tgz"
SPARK_URL="https://dlcdn.apache.org/spark/spark-3.5.7/$SPARK_TAR"
# å¤‡ç”¨æºï¼ˆå›½å†…åŠ é€Ÿï¼‰
BACKUP_URL="https://mirrors.aliyun.com/apache/spark/spark-3.5.7/$SPARK_TAR"

if [ ! -d "$SPARK_HOME" ]; then
  su - spark -c "
    cd /home/spark
    echo 'ğŸ“¥ ä»ä¸»æºä¸‹è½½Sparkï¼ˆæ˜¾ç¤ºè¿›åº¦ï¼‰...'
    if ! wget --show-progress --retry-connrefused --waitretry=3 --read-timeout=30 --timeout=15 -t 5 $SPARK_URL; then
      echo 'âŒ ä¸»æºä¸‹è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æº...'
      if ! wget --show-progress --retry-connrefused --waitretry=3 --read-timeout=30 --timeout=15 -t 5 $BACKUP_URL; then
        echo 'âŒ å¤‡ç”¨æºä¸‹è½½ä¹Ÿå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥'
        exit 1
      fi
    fi
    echo 'ï¿½è§£å‹Sparkå®‰è£…åŒ…...'
    if ! tar -xzf $SPARK_TAR; then
      echo 'âŒ è§£å‹å¤±è´¥ï¼Œå®‰è£…åŒ…å¯èƒ½æŸå'
      exit 1
    fi
    mv spark-3.5.7-bin-hadoop3 spark
    rm -f $SPARK_TAR  # æ¸…ç†å®‰è£…åŒ…
    echo 'âœ… Sparkå®‰è£…æˆåŠŸ'
  "
else
  echo "âœ… Sparkå·²å®‰è£…ï¼Œè·³è¿‡æ­¤æ­¥éª¤"
fi
chown -R spark:spark /home/spark/spark

# 4. é…ç½®ç¯å¢ƒå˜é‡
echo "æ­¥éª¤4ï¼šé…ç½®ç¯å¢ƒå˜é‡"
su - spark -c "
  cat >> ~/.bashrc << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export SPARK_HOME=/home/spark/spark
export PATH=\$PATH:\$SPARK_HOME/bin:\$SPARK_HOME/sbin
EOF
"

# 5. é…ç½®spark-env.shï¼ˆæ˜¾å¼å¯¼å‡ºSPARK_HOMEï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰
echo "æ­¥éª¤5ï¼šé…ç½®spark-env.sh"
su - spark -c "
  export SPARK_HOME=/home/spark/spark
  cp \$SPARK_HOME/conf/spark-env.sh.template \$SPARK_HOME/conf/spark-env.sh
  cat >> \$SPARK_HOME/conf/spark-env.sh << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export SPARK_MASTER_HOST=\$(hostname -i)
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_MEMORY=6g
export SPARK_WORKER_CORES=2
EOF
"

# 6. é…ç½®å…å¯†ç™»å½•ï¼ˆæœ¬åœ°ï¼‰
echo "æ­¥éª¤6ï¼šç”ŸæˆSSHå¯†é’¥"
su - spark -c "
  mkdir -p ~/.ssh
  chmod 700 ~/.ssh
  ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa -q  # æ— å¯†ç å¯†é’¥
  cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  chmod 600 ~/.ssh/authorized_keys
"

# 7. å¯åŠ¨Master
echo "æ­¥éª¤7ï¼šå¯åŠ¨Spark Master"
su - spark -c "$SPARK_HOME/sbin/start-master.sh"

echo "===== Spark Masterå®‰è£…å®Œæˆ ====="