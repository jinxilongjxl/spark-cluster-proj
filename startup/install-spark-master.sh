#!/bin/bash
set -e  
exec > /var/log/spark-master-install.log 2>&1

echo "=============================="
echo "ğŸš€ Starting Spark Master Installation"
echo "=============================="

# æ­¥éª¤1ï¼šæ›´æ–°ç³»ç»ŸåŒ…
echo "ğŸ”§ Step 1: Updating system packages..."
apt update -y
apt upgrade -y
echo "âœ… System packages updated"

# æ­¥éª¤2ï¼šå®‰è£… Java + ä¾èµ–
echo "ğŸ”§ Step 2: Installing OpenJDK 11..."
apt install -y openjdk-11-jdk
echo "âœ… Java installed: $(java -version 2>&1 | head -1)"

# æ­¥éª¤3ï¼šåˆ›å»º spark ç”¨æˆ·
echo "ğŸ‘¤ Step 3: Creating spark user..."
id spark &>/dev/null || useradd -m -s /bin/bash spark
echo "âœ… spark user created"

# æ­¥éª¤4ï¼šå®‰è£… Spark
echo "ğŸ“¦ Step 4: Installing Spark 3.4.1..."
SPARK_HOME="/home/spark/spark"
if [ ! -d "$SPARK_HOME" ]; then
  su - spark -c "
    cd /home/spark
    echo 'ğŸ“¥ Downloading Spark...'
    wget -q https://dlcdn.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz || exit 1
    echo 'ğŸ” Extracting Spark...'
    tar -xzf spark-3.4.1-bin-hadoop3.tgz || exit 1
    mv spark-3.4.1-bin-hadoop3 spark
    echo 'âœ… Spark installed successfully.'
  "
else
  echo "âœ… Spark already installed"
fi

# æ­¥éª¤5ï¼šé…ç½®ç¯å¢ƒå˜é‡ï¼ˆå¹¶ä¿®å¤æƒé™ï¼‰
echo "âš™ï¸ Step 5: Configuring environment variables..."
cat > /home/spark/.bashrc << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export SPARK_HOME=/home/spark/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
EOF
chown spark:spark /home/spark/.bashrc  # ä¿®å¤æ‰€æœ‰è€…
echo "âœ… .bashrc configured"

# æ­¥éª¤6ï¼šé…ç½® spark-env.shï¼ˆå¹¶ä¿®å¤æƒé™ï¼‰
echo "âš™ï¸ Step 6: Configuring spark-env.sh..."
cat >> $SPARK_HOME/conf/spark-env.sh << 'EOF'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export SPARK_MASTER_HOST=$(hostname -i)
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_MEMORY=2g
export SPARK_WORKER_CORES=1
EOF
chown spark:spark $SPARK_HOME/conf/spark-env.sh  # ä¿®å¤æƒé™
echo "âœ… spark-env.sh updated"

# æ­¥éª¤7ï¼šç”Ÿæˆ spark ç”¨æˆ·çš„ SSH å¯†é’¥ï¼ˆç”¨äºå…å¯†ç™»å½•ï¼‰
echo "ğŸ”‘ Step 7: Generating SSH key for spark user..."
su - spark -c "
  echo 'Generating SSH key pair...'
  ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa -q  # æ— å¯†ç ç”Ÿæˆå¯†é’¥
  # æ£€æŸ¥å…¬é’¥æ˜¯å¦ç”ŸæˆæˆåŠŸ
  if [ ! -f ~/.ssh/id_rsa.pub ]; then
    echo 'âŒ Failed to generate SSH public key'
    exit 1  # ç”Ÿæˆå¤±è´¥åˆ™è„šæœ¬é€€å‡º
  fi
  chmod 700 ~/.ssh
  cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  chmod 600 ~/.ssh/authorized_keys
  echo 'âœ… SSH key generated for localhost'
"

# æ­¥éª¤8ï¼šå¯åŠ¨ Spark Masterï¼ˆä»¥ spark ç”¨æˆ·è¿è¡Œï¼‰
echo "ğŸš€ Step 8: Starting Spark Master..."
su - spark -c "$SPARK_HOME/sbin/start-master.sh"
echo "âœ… Spark Master started"

echo "=============================="
echo "ğŸ‰ Spark Master Installation Completed!"
echo "=============================="